{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "635568e4-e816-40f7-8c7e-cfc051cfe9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in ./my-env/lib/python3.11/site-packages (8.1.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./my-env/lib/python3.11/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./my-env/lib/python3.11/site-packages (from ipywidgets) (8.21.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./my-env/lib/python3.11/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.10 in ./my-env/lib/python3.11/site-packages (from ipywidgets) (4.0.10)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.10 in ./my-env/lib/python3.11/site-packages (from ipywidgets) (3.0.10)\n",
      "Requirement already satisfied: decorator in ./my-env/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./my-env/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./my-env/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./my-env/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./my-env/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in ./my-env/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: pexpect>4.3 in ./my-env/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./my-env/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./my-env/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./my-env/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./my-env/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./my-env/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./my-env/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./my-env/lib/python3.11/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ea6086f-b746-4224-b2bb-73e26e162ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./my-env/lib/python3.11/site-packages (4.37.2)\n",
      "Requirement already satisfied: datasets in ./my-env/lib/python3.11/site-packages (2.17.1)\n",
      "Requirement already satisfied: torch in ./my-env/lib/python3.11/site-packages (2.2.0)\n",
      "Requirement already satisfied: pillow in ./my-env/lib/python3.11/site-packages (10.2.0)\n",
      "Requirement already satisfied: filelock in ./my-env/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./my-env/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.17 in ./my-env/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./my-env/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./my-env/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./my-env/lib/python3.11/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./my-env/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./my-env/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./my-env/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./my-env/lib/python3.11/site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in ./my-env/lib/python3.11/site-packages (from datasets) (15.0.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./my-env/lib/python3.11/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in ./my-env/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in ./my-env/lib/python3.11/site-packages (from datasets) (2.2.0)\n",
      "Requirement already satisfied: xxhash in ./my-env/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./my-env/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in ./my-env/lib/python3.11/site-packages (from datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in ./my-env/lib/python3.11/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./my-env/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./my-env/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./my-env/lib/python3.11/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./my-env/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./my-env/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./my-env/lib/python3.11/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./my-env/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./my-env/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./my-env/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./my-env/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./my-env/lib/python3.11/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./my-env/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./my-env/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./my-env/lib/python3.11/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./my-env/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./my-env/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./my-env/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./my-env/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./my-env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets torch pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa22ec0d-fedd-4deb-845f-396dc1d189d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, BlipForConditionalGeneration, AutoModelForCausalLM, AutoProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c93dd02-078f-489c-b2d2-fad7a3e553b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default num threads for intraop parallelism:  4\n",
      "default num threads for interop parallelism:  4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.set_num_threads(4) # intraop parallelism on CPU\n",
    "torch.set_num_interop_threads(4) # interop parallelism on CPU\n",
    "print(\"default num threads for intraop parallelism: \", torch.get_num_threads())\n",
    "print(\"default num threads for interop parallelism: \", torch.get_num_interop_threads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8a9deab-1c11-44f4-b447-cd639c5685d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "blip_model = BlipForConditionalGeneration.from_pretrained(\"../models/blip-large/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1983e496-594a-4d9f-a0bc-705bf1c466c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BlipForConditionalGeneration(\n",
       "  (vision_model): BlipVisionModel(\n",
       "    (embeddings): BlipVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))\n",
       "    )\n",
       "    (encoder): BlipEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x BlipEncoderLayer(\n",
       "          (self_attn): BlipAttention(\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (projection): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): BlipMLP(\n",
       "            (activation_fn): GELUActivation()\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (text_decoder): BlipTextLMHeadModel(\n",
       "    (bert): BlipTextModel(\n",
       "      (embeddings): BlipTextEmbeddings(\n",
       "        (word_embeddings): Embedding(30524, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): BlipTextEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x BlipTextLayer(\n",
       "            (attention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (crossattention): BlipTextAttention(\n",
       "              (self): BlipTextSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=1024, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): BlipTextSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BlipTextIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BlipTextOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (cls): BlipTextOnlyMLMHead(\n",
       "      (predictions): BlipTextLMPredictionHead(\n",
       "        (transform): BlipTextPredictionHeadTransform(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (transform_act_fn): GELUActivation()\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (decoder): Linear(in_features=768, out_features=30524, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blip_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91f7ee0c-3560-4a26-b688-420978e65528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469732924"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blip_model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d8eed5e1-ef76-4c4a-8a77-a0a53f1c944a",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_model = AutoModelForCausalLM.from_pretrained(\"../models/git-large/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "360c55c9-74e4-41e8-ad33-ad99ab8dd109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "394196026"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_model.num_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ea2ba2b-f573-4937-a2c9-7af0e5e1231c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GitForCausalLM(\n",
       "  (git): GitModel(\n",
       "    (embeddings): GitEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(1024, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (image_encoder): GitVisionModel(\n",
       "      (vision_model): GitVisionTransformer(\n",
       "        (embeddings): GitVisionEmbeddings(\n",
       "          (patch_embedding): Conv2d(3, 1024, kernel_size=(14, 14), stride=(14, 14), bias=False)\n",
       "          (position_embedding): Embedding(257, 1024)\n",
       "        )\n",
       "        (pre_layrnorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (encoder): GitVisionEncoder(\n",
       "          (layers): ModuleList(\n",
       "            (0-23): 24 x GitVisionEncoderLayer(\n",
       "              (self_attn): GitVisionAttention(\n",
       "                (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "              (mlp): GitVisionMLP(\n",
       "                (activation_fn): QuickGELUActivation()\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "              )\n",
       "              (layer_norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (post_layernorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (encoder): GitEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-5): 6 x GitLayer(\n",
       "          (attention): GitAttention(\n",
       "            (self): GitSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): GitSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): GitIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): GitOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (visual_projection): GitProjection(\n",
       "      (visual_projection): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=768, bias=True)\n",
       "        (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=768, out_features=30522, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "197751bd-0f15-4c97-92c0-b6a83c1025c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "blip_processor = BlipProcessor.from_pretrained(\"../models/blip-large/\")\n",
    "git_processor = AutoProcessor.from_pretrained(\"../models/git-large/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8afdd8c7-d2de-423b-a59f-c819eb5a7501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image_path = '/Users/naormatania/code/image-captioning/datasets/website-screenshots/test/file_71.jpg'\n",
    "img = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64ac0244-ad19-44d6-b77a-89ce135c770f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.94 s, sys: 326 ms, total: 9.26 s\n",
      "Wall time: 8.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blip_inputs = blip_processor(images=img, return_tensors=\"pt\")\n",
    "blip_out = blip_model.generate(**blip_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5706786b-35e5-471e-bbc2-e76f909647ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/naormatania/code/image-captioning/notebooks/my-env/lib/python3.11/site-packages/transformers/generation/utils.py:1133: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.3 s, sys: 2.45 s, total: 37.8 s\n",
      "Wall time: 34.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blip_inputs = blip_processor(images=[img]*4, return_tensors=\"pt\")\n",
    "blip_out = blip_model.generate(**blip_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9a627ee-67f8-4875-889e-dffaf50844b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.5 s, sys: 3.29 s, total: 16.8 s\n",
      "Wall time: 19.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "git_inputs = git_processor(images=img, return_tensors=\"pt\")\n",
    "git_out = git_model.generate(**git_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "111affa8-820a-4aa9-9ad8-c51202fde4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.9 s, sys: 3.12 s, total: 52 s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "git_inputs = git_processor(images=[img]*4, return_tensors=\"pt\")\n",
    "git_out = git_model.generate(**git_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e494c81-49a3-4c53-acff-b782e775f36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_blip = torch.compile(blip_model)\n",
    "compiled_git = torch.compile(git_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc50aca4-d6a2-46b1-8662-871192a10ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.6 s, sys: 1.62 s, total: 36.3 s\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "blip_out = compiled_blip.generate(**blip_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7fb4eb29-46bf-4f50-b7cf-a14dcc471b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 48.1 s, sys: 2.65 s, total: 50.8 s\n",
      "Wall time: 44.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "git_out = compiled_git.generate(**git_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fe706ff3-5728-45e3-9002-5ad42a791a87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qt/bczh05655z57blf3r39zzh780000gn/T/ipykernel_90279/1560711055.py:2: DeprecationWarning: activeCount() is deprecated, use active_count() instead\n",
      "  threading.activeCount()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import threading\n",
    "threading.activeCount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dfcf84d-05c4-4dd9-9cd1-df293ccc6471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.cpu_count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac7fcab4-f448-4874-9ab7-1d076ccbf4d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6876542d-8413-43be-a262-78bc2113b896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_class',\n",
       " '_create_repo',\n",
       " '_get_arguments_from_pretrained',\n",
       " '_get_files_timestamps',\n",
       " '_upload_modified_files',\n",
       " 'attributes',\n",
       " 'batch_decode',\n",
       " 'current_processor',\n",
       " 'decode',\n",
       " 'feature_extractor_class',\n",
       " 'from_args_and_dict',\n",
       " 'from_pretrained',\n",
       " 'get_processor_dict',\n",
       " 'image_processor',\n",
       " 'image_processor_class',\n",
       " 'model_input_names',\n",
       " 'push_to_hub',\n",
       " 'register_for_auto_class',\n",
       " 'save_pretrained',\n",
       " 'to_dict',\n",
       " 'to_json_file',\n",
       " 'to_json_string',\n",
       " 'tokenizer',\n",
       " 'tokenizer_class']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(git_processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3675f7a1-49e9-42aa-9b1e-65f42afe4687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'screens', '##hot', 'of', 'a', 'website']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "git_processor.tokenizer.tokenize('a screenshot of a website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c316901-1b21-4405-bcaf-e656dcd2e0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'screens', '##hot', 'of', 'a', 'website']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blip_processor.tokenizer.tokenize('a screenshot of a website')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a30b7f4c-dcbe-411f-a5ef-e0f9c785fd80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'AutoModelConditionalGeneration' from 'transformers' (/Users/naormatania/code/image-captioning/notebooks/my-env/lib/python3.11/site-packages/transformers/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AutoModelConditionalGeneration\n\u001b[1;32m      3\u001b[0m bm \u001b[38;5;241m=\u001b[39m AutoModelConditionalGeneration\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../models/blip-large/\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'AutoModelConditionalGeneration' from 'transformers' (/Users/naormatania/code/image-captioning/notebooks/my-env/lib/python3.11/site-packages/transformers/__init__.py)"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelConditionalGeneration\n",
    "\n",
    "bm = AutoModelConditionalGeneration.from_pretrained(\"../models/blip-large/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "940d1e47-a9d5-4a5f-b222-ddb4ef6508ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61f76d30c5084c36869bb37c24431337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770b9224010f48f799adb4fcb98bff4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2878b0244b01457a831b89453f969639",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image_id', 'caption_id', 'caption', 'height', 'width', 'file_name', 'coco_url', 'image_path'],\n",
       "        num_rows: 591753\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image_id', 'caption_id', 'caption', 'height', 'width', 'file_name', 'coco_url', 'image_path'],\n",
       "        num_rows: 25014\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image_id', 'caption_id', 'caption', 'height', 'width', 'file_name', 'coco_url', 'image_path'],\n",
       "        num_rows: 40670\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"ydshieh/coco_dataset_script\", \"2017\", data_dir=\"/Users/naormatania/code/image-captioning/datasets\")\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2baa2943-1750-47b6-9b47-825aa9b4abcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "000000179765.jpg\n",
      "A black Honda motorcycle parked in front of a garage.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "print(os.path.basename(ds['validation'][0]['image_path']))\n",
    "print(ds['validation'][0]['caption'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d98aacd-9ad5-4eae-8639-3b7f0d05d8df",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'cwd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcwd\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'os' has no attribute 'cwd'"
     ]
    }
   ],
   "source": [
    "os.cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4d47759-caa6-4d13-9533-82563d3259e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlipProcessor, AutoProcessor\n",
    "processor = BlipProcessor.from_pretrained(\"../models/blip-large/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ffe5a7f-e91d-4c6b-bc26-6c358f39ca2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='../models/blip-large/', vocab_size=30522, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed7d8d-c901-4888-8cc2-cd6a10521117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
